{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hyYNTPtMEVFS"
      },
      "source": [
        "# MNIST Single Layer Network with TensorBoard"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4mpClHxXL51l"
      },
      "source": [
        "Note: This notebook is desinged to run with Python3 and GPU runtime.\n",
        "\n",
        "![Python 3 and CPU runtime](https://raw.githubusercontent.com/enakai00/colab_tfbook/master/docs/imgs/runtime_gpu.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eEcsPed9AUfE"
      },
      "source": [
        "This notebook uses TensorFlow2.x."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N4qbP7L1QSqR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0cfb829c-dbfa-4ee7-d47f-59fcb798d7ff"
      },
      "source": [
        "%tensorflow_version 2.x"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 2.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iMh9oOgFUi0a"
      },
      "source": [
        "Update packages that are requried to run TensorBoard."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R3oahUDYUfqX"
      },
      "source": [
        "!pip2 install --upgrade google-auth-oauthlib grpcio >/dev/null 2>&1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VJO3PPzqsq8d"
      },
      "source": [
        "####[MST-01]\n",
        "Import modules and set random seeds."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gB5UUoAXIVmC"
      },
      "source": [
        "import numpy as np\n",
        "import shutil\n",
        "os.environ['TF_USE_LEGACY_KERAS'] = '1'\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models, initializers, callbacks\n",
        "from tensorflow.keras.datasets import mnist\n",
        "\n",
        "np.random.seed(20190228)\n",
        "tf.random.set_seed(20190228)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yz2h7_8St1wi"
      },
      "source": [
        "####[MST-02]\n",
        "Download the MNIST dataset and store into NumPy arrays."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ASgzWK5AjWvn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "731a32ca-6473-45ee-8892-d169be497d42"
      },
      "source": [
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
        "train_images = train_images.reshape(\n",
        "                  (len(train_images), 784)).astype('float32') / 255\n",
        "test_images = test_images.reshape(\n",
        "                  (len(test_images), 784)).astype('float32') / 255\n",
        "train_labels = tf.keras.utils.to_categorical(train_labels, 10)\n",
        "test_labels = tf.keras.utils.to_categorical(test_labels, 10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qdQ0Tp2IvFy8"
      },
      "source": [
        "####[MST-03]\n",
        "Define a model with a single hidden layer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tpL_niBTXggS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "b8a2935e-4c1c-4f13-a626-f0f23a1cf94d"
      },
      "source": [
        "model = models.Sequential()\n",
        "model.add(layers.Dense(1024, activation='relu', input_shape=(28*28,),\n",
        "                       kernel_initializer=initializers.TruncatedNormal(),\n",
        "                       name='hidden'))\n",
        "model.add(layers.Dense(10, activation='softmax', name='softmax'))\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "hidden (Dense)               (None, 1024)              803840    \n",
            "_________________________________________________________________\n",
            "softmax (Dense)              (None, 10)                10250     \n",
            "=================================================================\n",
            "Total params: 814,090\n",
            "Trainable params: 814,090\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fBltXsSRvZn0"
      },
      "source": [
        "####[MST-04]\n",
        "Compile the model using the Adam optimizer, and Cross entroy as a loss function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BakcuKxdQoSL"
      },
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['acc'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fdIktV-vFDof"
      },
      "source": [
        "####[MST-05]\n",
        "Train the model with the callbacks option to store training logs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LlQCTsKKXkr5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        },
        "outputId": "3f73a96c-0b7a-4d0b-ef7c-3407b4ea85f0"
      },
      "source": [
        "log_dir = '/tmp/log'\n",
        "shutil.rmtree(log_dir, ignore_errors=True)\n",
        "tensorboard_callback = callbacks.TensorBoard(log_dir=log_dir,\n",
        "                                             histogram_freq=1)\n",
        "history = model.fit(train_images, train_labels,\n",
        "                    validation_data=(test_images, test_labels),\n",
        "                    batch_size=128, epochs=10,\n",
        "                    callbacks=[tensorboard_callback])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 4s 74us/sample - loss: 0.2310 - acc: 0.9338 - val_loss: 0.1176 - val_acc: 0.9655\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 3s 46us/sample - loss: 0.0908 - acc: 0.9737 - val_loss: 0.0821 - val_acc: 0.9747\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 3s 46us/sample - loss: 0.0557 - acc: 0.9834 - val_loss: 0.0662 - val_acc: 0.9797\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 3s 47us/sample - loss: 0.0390 - acc: 0.9887 - val_loss: 0.0621 - val_acc: 0.9804\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 3s 45us/sample - loss: 0.0252 - acc: 0.9926 - val_loss: 0.0579 - val_acc: 0.9826\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 3s 44us/sample - loss: 0.0189 - acc: 0.9947 - val_loss: 0.0619 - val_acc: 0.9810\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 3s 44us/sample - loss: 0.0148 - acc: 0.9958 - val_loss: 0.0567 - val_acc: 0.9827\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 3s 43us/sample - loss: 0.0098 - acc: 0.9977 - val_loss: 0.0647 - val_acc: 0.9805\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 3s 44us/sample - loss: 0.0092 - acc: 0.9974 - val_loss: 0.0682 - val_acc: 0.9814\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 3s 44us/sample - loss: 0.0105 - acc: 0.9969 - val_loss: 0.0655 - val_acc: 0.9826\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MpSePiAysZHn"
      },
      "source": [
        "####[MST-06]\n",
        "Install ngrok to run TensorBoard on Colaboratory."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BqHkMyJHYFTb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "9315cbea-e638-4e72-c27d-0aed3125a047"
      },
      "source": [
        "!curl -OL https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
        "!unzip -o ngrok-stable-linux-amd64.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 12.9M  100 12.9M    0     0  20.8M      0 --:--:-- --:--:-- --:--:-- 20.7M\n",
            "Archive:  ngrok-stable-linux-amd64.zip\n",
            "  inflating: ngrok                   \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VCHxA0sKahqD"
      },
      "source": [
        "####[MST-07]\n",
        "Start TensorBoard and prepare the connection URL."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o3oGrHRwWz58",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ab8e9292-9e8a-48b9-daca-718c1c886c84"
      },
      "source": [
        "get_ipython().system_raw(\n",
        "    'tensorboard --logdir {} --host 0.0.0.0 --port 6006 &'\n",
        "    .format(log_dir)\n",
        ")\n",
        "get_ipython().system_raw('./ngrok http 6006 &')\n",
        "!curl -s http://localhost:4040/api/tunnels | python3 -c \\\n",
        "    \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "http://b21140f1.ngrok.io\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}